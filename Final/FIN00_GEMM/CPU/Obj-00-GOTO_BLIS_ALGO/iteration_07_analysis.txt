ITERATION 7: tuned_variant04_op_block_nr
================================================================================

1. CODE CHANGES FROM PREVIOUS ITERATION
--------------------------------------------------------------------------------
Comparing tuned_variant03_op_block_mc.c -> tuned_variant04_op_block_nr.c

Key changes detected:
  - BLOCK_NC (n-dimension blocking) introduced/modified
  - BLOCK_KC (k-dimension blocking) introduced/modified
  - BLOCK_MC (m-dimension blocking) introduced/modified
  - BLOCK_NR (micro-kernel n blocking) introduced/modified
  - OpenMP/threading introduced

Diff excerpt (first 100 lines of changes):
--- Obj-00-GOTO_BLIS_ALGO/tuned_variant03_op_block_mc.c	2025-12-05 03:05:55.598484631 +0000
+++ Obj-00-GOTO_BLIS_ALGO/tuned_variant04_op_block_nr.c	2025-12-05 03:05:55.598484631 +0000
+#ifndef BLOCK_NR
+#define BLOCK_NR 6
+#endif /* BLOCK_NR */
+
+/* ASSERTIONS: We want block sizes to nest perfectly. */
+#if (BLOCK_NC) % (BLOCK_NR) != 0
+#error "NR must be a factor of NC.\n"
+#endif
+
-
-	The following loops represent the bulk of the computation
-	and will be the main focus of the remaining optimizations.
-	Once we have the data layout transformation we will bring
-	the fringe code back into the steady-state. Until then our
-	optimizations will be much easier to perform if we do not
-	need to think about corner cases.
-
-	Additionally, there are some asymmetries that we will need
-	to consider. The main one is that accesses to A and B are
-	only reads, whereas accesses to C will require both a load
-	and store. This will help determine where we place the KC
-	loop as it will amortize those load/stores with KC number
-	of FMA instructions.
-		for( int j0_i = 0; j0_i < BLOCK_NC; ++j0_i )
+		for( int j0_i = 0; j0_i < BLOCK_NC; j0_i += BLOCK_NR )
-		    // Note: This will be moved in later iterations
-		      {
-			int j0 = j0_o + j0_i;
-			int i0 = i0_o + i0_i;
-			int p0 = p0_o + p0_i;
-			float A_ip = A_distributed[i0 * cs_A + p0 * rs_A];
-			float B_pj = B_distributed[p0 * cs_B + j0 * rs_B];
+		      for( int j0_r = 0; j0_r < BLOCK_NR; ++j0_r  )
+			{
+			  int j0 = j0_o + j0_i + j0_r;
+			  int i0 = i0_o + i0_i;
+			  int p0 = p0_o + p0_i;
+			  float A_ip = A_distributed[i0 * cs_A + p0 * rs_A];
+			  float B_pj = B_distributed[p0 * cs_B + j0 * rs_B];
-			C_distributed[i0 * cs_C + j0 * rs_C]  += A_ip*B_pj;
-		      }
+			  C_distributed[i0 * cs_C + j0 * rs_C]  += A_ip*B_pj;
+			}
-
...


2. PERFORMANCE ANALYSIS
--------------------------------------------------------------------------------
Performance data from CSV files:

Performance data not available in CSV format

Corresponding plot: results/plot_iter_07_tuned_variant04_op_block_nr.png


3. EXPLANATION AND HYPOTHESIS
--------------------------------------------------------------------------------
BLOCK_NR introduces micro-kernel blocking for register-level optimization.
Small blocks are kept in registers for the innermost computation, enabling
better instruction-level parallelism and register reuse.

To test this hypothesis:
- Profile cache miss rates (perf stat -e cache-misses,cache-references)
- Analyze instruction mix and IPC (instructions per cycle)
- Vary block sizes to find optimal values for target architecture
- Compare performance across different matrix sizes and shapes
