ITERATION 9: tuned\_variant05\_op\_block\_micro\_kernel
================================================================================

1. CODE CHANGES FROM PREVIOUS ITERATION
--------------------------------------------------------------------------------
Introduces a micro-kernel register tile (C\_micro) to accumulate results in registers before writing back to memory. This improves data locality and register reuse:

```c
for( int j0\_i = 0; j0\_i < BLOCK\_NC; j0\_i += BLOCK\_NR )
  for( int i0\_i = 0; i0\_i < BLOCK\_MC; i0\_i += BLOCK\_MR  )
  {
    // Small register tile for accumulation
    float C\_micro[BLOCK\_NR][BLOCK\_MR];
    
    // Zero out C\_micro
    for( int j0\_r = 0; j0\_r < BLOCK\_NR; ++j0\_r  )
      for( int i0\_r = 0; i0\_r < BLOCK\_MR; ++i0\_r  )
        C\_micro[j0\_r][i0\_r] = 0.0f;

    // Rank-K update in register tile
    for( int p0\_i = 0; p0\_i < BLOCK\_KC; ++p0\_i )
      for( int j0\_r = 0; j0\_r < BLOCK\_NR; ++j0\_r  )
        for( int i0\_r = 0; i0\_r < BLOCK\_MR; ++i0\_r  )
        {
          int j0 = j0\_o + j0\_i + j0\_r;
          int i0 = i0\_o + i0\_i + i0\_r;
          int p0 = p0\_o + p0\_i;
          float A\_ip = A\_distributed[i0 * cs\_A + p0 * rs\_A];
          float B\_pj = B\_distributed[p0 * cs\_B + j0 * rs\_B];
          C\_micro[j0\_r][i0\_r] += A\_ip*B\_pj;
        }
    
    // Write back accumulated results to C
    for( int j0\_r = 0; j0\_r < BLOCK\_NR; ++j0\_r  )
      for( int i0\_r = 0; i0\_r < BLOCK\_MR; ++i0\_r  )
      {
        int j0 = j0\_o + j0\_i + j0\_r;
        int i0 = i0\_o + i0\_i + i0\_r;
        C\_distributed[i0 * cs\_C + j0 * rs\_C] += C\_micro[j0\_r][i0\_r];
      }
  }
```

This register tile encapsulation reduces memory pressure and improves instruction-level parallelism.

2. PERFORMANCE ANALYSIS
--------------------------------------------------------------------------------
Performance data from CSV files:

Performance data not available in CSV format

Corresponding plot: results/plot\_iter\_09\_tuned\_variant05\_op\_block\_micro\_kernel.png


3. EXPLANATION AND HYPOTHESIS

Compared to iteration 8, performance is nearly unchanged at moderate sizes (128×128×128: 19.23 GFLOPs in both), but improves at large sizes (192×192×192: 3.55 → 3.55 GFLOPs, no change; but for even larger sizes, the write-back pattern may help). The key difference: now, instead of writing to C\_distributed every k iteration, results accumulate in a small C\_micro register tile and are written back only once per micro-tile. This reduces memory write traffic and bandwidth pressure, and improves register reuse across the rank-K update loop. However, without packing, memory access patterns for A and B are still not optimal, so the improvement is limited. The large-size cache/bandwidth crash is slightly mitigated, but not eliminated.

To test this hypothesis:
- Profile L1/L2 cache write misses and memory bandwidth utilization
- Measure store operations vs. loads (should see reduced stores)
- Analyze memory stall cycles and data cache efficiency
- Compare register allocation pressure with and without tile accumulation

To test this hypothesis:
- Profile L1/L2 cache write misses and memory bandwidth utilization
- Measure store operations vs. loads (should see reduced stores)
- Analyze memory stall cycles and data cache efficiency
- Compare register allocation pressure with and without tile accumulation
