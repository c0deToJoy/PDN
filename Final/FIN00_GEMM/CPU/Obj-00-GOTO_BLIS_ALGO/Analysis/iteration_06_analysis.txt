ITERATION 6: tuned\_variant03\_op\_block\_mc
================================================================================

1. CODE CHANGES FROM PREVIOUS ITERATION
--------------------------------------------------------------------------------
Adds BLOCK\_MC (m-dimension blocking, default 128) to complete the 3-level cache hierarchy:

```c
int n0\_fringe\_start = n0 - (n0\%(BLOCK\_NC));
int k0\_fringe\_start = k0 - (k0\%(BLOCK\_KC));
int m0\_fringe\_start = m0 - (m0\%(BLOCK\_MC));

// Steady State
for( int j0\_o = 0; j0\_o < n0\_fringe\_start; j0\_o += BLOCK\_NC )
  {
    for( int p0\_o = 0; p0\_o < k0\_fringe\_start; p0\_o += BLOCK\_KC )
      {
        for( int i0\_o = 0; i0\_o < m0\_fringe\_start; i0\_o += BLOCK\_MC )
          for( int j0\_i = 0; j0\_i < BLOCK\_NC; ++j0\_i )
            for( int i0\_i = 0; i0\_i < BLOCK\_MC; ++i0\_i  )
              for( int p0\_i = 0; p0\_i < BLOCK\_KC; ++p0\_i )
                {
                  int j0 = j0\_o + j0\_i;
                  int i0 = i0\_o + i0\_i;
                  int p0 = p0\_o + p0\_i;
                  float A\_ip = A\_distributed[i0 * cs\_A + p0 * rs\_A];
                  float B\_pj = B\_distributed[p0 * cs\_B + j0 * rs\_B];
                  C\_distributed[i0 * cs\_C + j0 * rs\_C]  += A\_ip*B\_pj;
                }

        // Fringe for m0
        for( int i0 = m0\_fringe\_start; i0 < m0; ++i0 )
          for( int j0\_i = 0; j0\_i < BLOCK\_NC; ++j0\_i )
            for( int p0\_i = 0; p0\_i < BLOCK\_KC; ++p0\_i )
              {
                int j0 = j0\_o + j0\_i;
                int p0 = p0\_o + p0\_i;
                float A\_ip = A\_distributed[i0 * cs\_A + p0 * rs\_A];
                float B\_pj = B\_distributed[p0 * cs\_B + j0 * rs\_B];
                C\_distributed[i0 * cs\_C + j0 * rs\_C]  += A\_ip*B\_pj;
              }
      }
  }
```

Now all three dimensions are blocked: NC for L3, KC for L2, and MC for L1, creating a nested structure where small tiles of C (BLOCK\_MC × BLOCK\_NC) fit in L1 cache.

2. PERFORMANCE ANALYSIS
--------------------------------------------------------------------------------
Performance data from CSV files (GFLOPs, 2 ranks):
- Iteration 5 (NC+KC): 128×128×128 = 28.92; 192×192×192 = 2.23
- Iteration 6 (NC+KC+MC): 128×128×128 = 19.37; 192×192×192 = 2.29

Corresponding plot: results/plot_iter_06_tuned_variant03_op_block_mc.png


3. EXPLANATION AND HYPOTHESIS
--------------------------------------------------------------------------------
BLOCK\_MC adds blocking in the m-dimension (rows of C), creating the full
3-level cache hierarchy blocking structure. This ensures the micro-panel
of C fits in L1 cache while blocks of A and B fit in L2/L3, again, improving cache locality.

Why it should help: MC adds the final dimension of blocking so the C micro-panel (MC×NC) can stay in L1 while A/B panels stay in L2/L3, reducing cache misses versus a 2D block.

Why it actually regresses vs iteration 5: Without packing or a tuned microkernel, the extra MC loop shortens inner loops and adds index arithmetic, so compiler vectorization and register reuse suffer. MC=128 also increases loop overhead and does not fix the strided B accesses; A/B/C footprints still push LLC at larger sizes, so the large-size crash remains. Net effect: higher overhead at moderate sizes (128³ drops from 28.92 → 19.37 GFLOPs) with no relief at 192³ (still ~2.3 GFLOPs).

To validate and mitigate:
- Profile cache/branch events (perf stat -e cache-misses,cache-references,branches,branch-misses)
- Try smaller MC to lower overhead, or introduce packing + microkernel so MC blocking actually boosts reuse
- Recheck LLC fit after tuning MC/NC/KC to avoid the 192³ collapse
